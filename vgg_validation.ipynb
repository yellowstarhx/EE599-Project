{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yellowstarhx/EE599-Project/blob/master/vgg_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpHbdtFdyXO9",
        "colab_type": "code",
        "outputId": "ff3da59e-c6ae-4e8d-bf2d-7cab42f453d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCkwqoE5-28N",
        "colab_type": "code",
        "outputId": "ed90a1a8-059c-4c49-cf52-b71a4faae2b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# Reference: https://blog.csdn.net/rocachilles/article/details/87894808\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from skimage import io, transform\n",
        "import glob\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
        "\n",
        "test_path = '/content/drive/My Drive/test_vgg/'\n",
        "model_path = \"/content/drive/My Drive/model/vgg.ckpt\"\n",
        "\n",
        "w = 224\n",
        "h = 224\n",
        "c = 3\n",
        "n_class = 40\n",
        "\n",
        "def read_img(path):\n",
        "    cate   = [path + x for x in os.listdir(path) if os.path.isdir(path + x)]\n",
        "    imgs   = []\n",
        "    labels = []\n",
        "    label_list = np.eye(n_class)\n",
        "    for idx, folder in enumerate(cate):            #search folder\n",
        "        for im in glob.glob(folder + '/*.jpg'):    #change doc type if necessary\n",
        "            img = io.imread(im)\n",
        "            img = transform.resize(img, (w, h, c))\n",
        "            imgs.append(img)                        # (sum,224,224,3)\n",
        "            labels.append(label_list[idx])          # (sum,4)         \n",
        "        for im in glob.glob(folder + '/*.png'):    #change doc type if necessary\n",
        "            img = io.imread(im)\n",
        "            img = transform.resize(img, (w, h, c))\n",
        "            imgs.append(img)                        # (sum,224,224,3)\n",
        "            labels.append(label_list[idx])          # (sum,4)                         \n",
        "    return np.asarray(imgs, np.float32), np.asarray(labels, np.float32)\n",
        "\n",
        "data_t, label_t = read_img(test_path)\n",
        "   \n",
        "s_test = data_t.shape[0]                        \n",
        "arr = np.arange(s_test)                    \n",
        "# np.random.shuffle(arr)                           # random sequence\n",
        "x_val = data_t[arr]\n",
        "y_val = label_t[arr]\n",
        "\n",
        "#------------------vgg16 structure----------------\n",
        " \n",
        "x = tf.placeholder(tf.float32, shape=[None, h, w, c])\n",
        "y = tf.placeholder(tf.float32, shape=[None, n_class])     \n",
        "\n",
        "#----------------- conv1 ------------------------\n",
        "\n",
        "w_conv1_1 = tf.Variable(tf.truncated_normal([3, 3, 3, 64], stddev=0.1))\n",
        "b_conv1_1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "L_conv1_1 = tf.nn.relu(tf.nn.conv2d(x, w_conv1_1,strides=[1, 1, 1, 1], padding='SAME') + b_conv1_1)\n",
        "\n",
        "w_conv1_2 = tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1))\n",
        "b_conv1_2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "L_conv1_2 = tf.nn.relu(tf.nn.conv2d(L_conv1_1, w_conv1_2,strides=[1, 1, 1, 1], padding='SAME') + b_conv1_2)\n",
        "\n",
        "L_pool1 = tf.nn.max_pool(L_conv1_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "#----------------- conv2 ------------------------\n",
        "\n",
        "w_conv2_1 = tf.Variable(tf.truncated_normal([3, 3, 64, 128], stddev=0.1))\n",
        "b_conv2_1 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "L_conv2_1 = tf.nn.relu(tf.nn.conv2d(L_pool1, w_conv2_1,strides=[1, 1, 1, 1], padding='SAME') + b_conv2_1)\n",
        "\n",
        "w_conv2_2 = tf.Variable(tf.truncated_normal([3, 3, 128, 128], stddev=0.1))\n",
        "b_conv2_2 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "L_conv2_2 = tf.nn.relu(tf.nn.conv2d(L_conv2_1, w_conv2_2,strides=[1, 1, 1, 1], padding='SAME') + b_conv2_2)\n",
        "\n",
        "L_pool2 = tf.nn.max_pool(L_conv2_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "#-------------------conv3 -------------------------\n",
        "\n",
        "w_conv3_1 = tf.Variable(tf.truncated_normal([3, 3, 128, 256], stddev=0.1))\n",
        "b_conv3_1 = tf.Variable(tf.constant(0.1, shape=[256]))\n",
        "L_conv3_1 = tf.nn.relu(tf.nn.conv2d(L_pool2, w_conv3_1,strides=[1, 1, 1, 1], padding='SAME') + b_conv3_1)\n",
        "\n",
        "\n",
        "w_conv3_2 = tf.Variable(tf.truncated_normal([3, 3, 256, 256], stddev=0.1))\n",
        "b_conv3_2 = tf.Variable(tf.constant(0.1, shape=[256]))\n",
        "L_conv3_2 = tf.nn.relu(tf.nn.conv2d(L_conv3_1, w_conv3_2,strides=[1, 1, 1, 1], padding='SAME') + b_conv3_2)\n",
        "\n",
        "\n",
        "w_conv3_3 = tf.Variable(tf.truncated_normal([3, 3, 256, 256], stddev=0.1))\n",
        "b_conv3_3 = tf.Variable(tf.constant(0.1, shape=[256]))\n",
        "L_conv3_3 = tf.nn.relu(tf.nn.conv2d(L_conv3_2, w_conv3_3,strides=[1, 1, 1, 1], padding='SAME') + b_conv3_3)\n",
        "\n",
        "L_pool3 = tf.nn.max_pool(L_conv3_3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "#---------------------- conv4 -----------------------------------\n",
        "\n",
        "w_conv4_1 = tf.Variable(tf.truncated_normal([3, 3, 256, 512], stddev=0.1))\n",
        "b_conv4_1 = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "L_conv4_1 = tf.nn.relu(tf.nn.conv2d(L_pool3, w_conv4_1,strides=[1, 1, 1, 1], padding='SAME') + b_conv4_1)\n",
        "\n",
        "\n",
        "w_conv4_2 = tf.Variable(tf.truncated_normal([3, 3, 512, 512], stddev=0.1))\n",
        "b_conv4_2 = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "L_conv4_2 = tf.nn.relu(tf.nn.conv2d(L_conv4_1, w_conv4_2,strides=[1, 1, 1, 1], padding='SAME') + b_conv4_2)\n",
        "\n",
        "\n",
        "w_conv4_3 = tf.Variable(tf.truncated_normal([3, 3, 512, 512], stddev=0.1))\n",
        "b_conv4_3 = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "L_conv4_3 = tf.nn.relu(tf.nn.conv2d(L_conv4_2, w_conv4_3,strides=[1, 1, 1, 1], padding='SAME') + b_conv4_3)\n",
        "\n",
        "L_pool4 = tf.nn.max_pool(L_conv4_3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "#---------------------- conv5 -----------------------------------\n",
        "\n",
        "w_conv5_1 = tf.Variable(tf.truncated_normal([3, 3, 512, 512], stddev=0.1))\n",
        "b_conv5_1 = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "L_conv5_1 = tf.nn.relu(tf.nn.conv2d(L_pool4, w_conv5_1,strides=[1, 1, 1, 1], padding='SAME') + b_conv5_1)\n",
        "\n",
        "\n",
        "w_conv5_2 = tf.Variable(tf.truncated_normal([3, 3, 512, 512], stddev=0.1))\n",
        "b_conv5_2 = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "L_conv5_2 = tf.nn.relu(tf.nn.conv2d(L_conv5_1, w_conv5_2,strides=[1, 1, 1, 1], padding='SAME') + b_conv5_2)\n",
        "\n",
        "\n",
        "w_conv5_3 = tf.Variable(tf.truncated_normal([3, 3, 512, 512], stddev=0.1))\n",
        "b_conv5_3 = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "L_conv5_3 = tf.nn.relu(tf.nn.conv2d(L_conv5_2, w_conv5_3,strides=[1, 1, 1, 1], padding='SAME') + b_conv5_3)\n",
        "\n",
        "L_pool5 = tf.nn.max_pool(L_conv5_3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "#------------------------ fully connected 6 -------------------------------------\n",
        "shape6 = int(np.prod(L_pool5.get_shape()[1:]))   \n",
        "w_fc6 = tf.Variable(tf.truncated_normal([shape6, 4096], stddev=0.1))\n",
        "b_fc6 = tf.Variable(tf.constant(0.1, shape=[4096]))\n",
        "f_fc6 = tf.reshape(L_pool5, [-1, shape6])\n",
        "L_fc6 = tf.nn.relu(tf.matmul(f_fc6, w_fc6) + b_fc6)\n",
        "\n",
        "#------------------------  fully connected 7  ----------------------------\n",
        "\n",
        "# ---------------------- Drop --------------------------\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "d_fc7 = tf.nn.dropout(L_fc6, keep_prob)\n",
        "\n",
        "w_fc7 = tf.Variable(tf.truncated_normal([4096, 4096], stddev=0.1))\n",
        "b_fc7 = tf.Variable(tf.constant(0.1, shape=[4096]))\n",
        "L_fc7 = tf.nn.relu(tf.matmul(d_fc7, w_fc7) + b_fc7)\n",
        "\n",
        "#------------------------ fully connected 8 ------------------------------------\n",
        "\n",
        "w_fc8 = tf.Variable(tf.truncated_normal([4096, n_class], stddev=0.1))\n",
        "b_fc8 = tf.Variable(tf.constant(0.1, shape=[n_class]))\n",
        "L_fc8 = tf.matmul(L_fc7, w_fc8) + b_fc8\n",
        "\n",
        "#-------------------- final output -------------------------------\n",
        "\n",
        "# y_conv = tf.nn.softmax(L_fc8)\n",
        "y_conv = L_fc8\n",
        "y_ = tf.nn.softmax(L_fc8)\n",
        "\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
        "train_step = tf.train.AdamOptimizer((1e-4)).minimize(cross_entropy)\n",
        "prediction_cls = tf.argmax(y_conv,1) #the actual class\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# --------------- save the model ----------------------------\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "#------------------ run --------------------------------\n",
        "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "    print (\"Input %s images, %s labels\" % (s_test, s_test))\n",
        "    saver.restore(sess,model_path)\n",
        "    val_acc, val_loss, val_pre = sess.run([accuracy, cross_entropy, prediction_cls],feed_dict={x: x_val, y: y_val, keep_prob: 1.0})\n",
        "    print('Testing accuracy %s' % (val_acc))\n",
        "    print(\"Predicted class:\")\n",
        "    print(val_pre)\n",
        "print(\"actual class:\")\n",
        "print(arr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
            "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input 40 images, 40 labels\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/model/vgg.ckpt\n",
            "Testing accuracy 0.525\n",
            "Predicted class:\n",
            "[ 0 20 33  3 22 33 33 33  8 23 15 11 12 18 14 15 15 15 18 19 20 21 22 18\n",
            " 24 22 15 27 28 39 30 33 37 33 34 39 36 39 38 39]\n",
            "actual class:\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}